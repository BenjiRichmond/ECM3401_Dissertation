{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join('RUSSIA/PKL', \"*.pkl.gz\"))\n",
    "files_done = []\n",
    "for file in files:\n",
    "        df = pd.read_pickle(file)\n",
    "        comments_df_initial = df[df['in_reply_to_user_id_str'].notnull()].copy()\n",
    "        del df\n",
    "        temp_comments_df = pd.DataFrame({\n",
    "            'user_id': comments_df_initial['user.id_str'].apply(int),\n",
    "            'user_name': comments_df_initial['user.screen_name'],\n",
    "            'commented_user_id': comments_df_initial['in_reply_to_user_id_str'].apply(int),\n",
    "            'commented_user_name': comments_df_initial['in_reply_to_screen_name']\n",
    "        })\n",
    "        temp_comments_df = temp_comments_df[temp_comments_df['user_id'] != temp_comments_df['commented_user_id']]\n",
    "        files_done.append(temp_comments_df)\n",
    "comments_df = pd.concat(files_done, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_users = comments_df[['user_id', 'user_name']].rename(columns={'user_id': 'user_id', 'user_name': 'name'})\n",
    "\n",
    "df_commented = comments_df[['commented_user_id', 'commented_user_name']].rename(\n",
    "    columns={'commented_user_id': 'user_id', 'commented_user_name': 'name'}\n",
    ")\n",
    "index_df = pd.concat([df_users, df_commented]).drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_comments = comments_df.groupby(['user_id', 'commented_user_id']).size().reset_index(name='count')\n",
    "grouped_comments = grouped_comments.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in grouped_comments.iterrows():\n",
    "    G.add_edge(row['user_id'], row['commented_user_id'], weight=row['count'])\n",
    "\n",
    "nx.write_gexf(G, \"network_comment_RUS.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEPHI STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = pd.read_csv('COMMENT_NETWORK_RUS/RUSSIA COMMUNITIES.csv').rename(\n",
    "    columns={'Id': 'user_id', 'modularity_class': 'community'}\n",
    ")\n",
    "\n",
    "grouped_comments['user_id'] = grouped_comments['user_id'].astype(int)\n",
    "\n",
    "df_merged = pd.merge(grouped_comments, communities, on='user_id', how='inner').rename(columns={'community': 'community_user'})\n",
    "\n",
    "df_merged = pd.merge(df_merged, communities, left_on='commented_user_id', right_on='user_id', how='inner').rename(\n",
    "    columns={'community': 'community_commented_user'}\n",
    ")\n",
    "\n",
    "df_communities = df_merged.copy().rename(columns={'user_id_x': 'user_id'})\n",
    "df_same_community = df_merged[df_merged['community_user'] == df_merged['community_commented_user']].copy().rename(\n",
    "    columns={'user_id_x': 'user_id'}\n",
    ")\n",
    "df_same_community.drop(columns=['user_id_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound = df_communities.groupby([\"community_user\", \"community_commented_user\"])[\"count\"].sum().reset_index()\n",
    "\n",
    "inbound_graph = inbound.rename(columns={\n",
    "    \"community_user\": \"initiating_community\",\n",
    "    \"community_commented_user\": \"receiving_community\",\n",
    "    \"count\": \"weight\"\n",
    "})\n",
    "\n",
    "inbound_graph = inbound_graph[inbound_graph[\"initiating_community\"] != inbound_graph[\"receiving_community\"]]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for _, row in inbound_graph.iterrows():\n",
    "    source = row[\"initiating_community\"]\n",
    "    target = row[\"receiving_community\"]\n",
    "    weight = row[\"weight\"]\n",
    "    G.add_edge(source, target, weight=weight)\n",
    "\n",
    "nx.write_gexf(G, \"communities_comment_RUS.gexf\")\n",
    "\n",
    "inbound_pivot = inbound.pivot(index=\"community_user\", columns=\"community_commented_user\", values=\"count\").fillna(0)\n",
    "communities_list = sorted(set(inbound_pivot.index).union(inbound_pivot.columns))\n",
    "inbound_pivot = inbound_pivot.reindex(index=communities_list, columns=communities_list, fill_value=0)\n",
    "\n",
    "sym_df = pd.DataFrame(index=communities_list, columns=communities_list, data=0)\n",
    "for i in communities_list:\n",
    "    for j in communities_list:\n",
    "        sym_df.loc[i, j] = inbound_pivot.loc[i, j] + inbound_pivot.loc[j, i]\n",
    "\n",
    "sym_df[\"Percentage_Self\"] = [\n",
    "    (sym_df.loc[i, i] / sym_df.loc[i].sum() * 100) if sym_df.loc[i].sum() != 0 else 0\n",
    "    for i in sym_df.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_results = []\n",
    "\n",
    "for community_user, group in df_same_community.groupby('community_user'):\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in group.iterrows():\n",
    "        G.add_edge(row['user_id'], row['commented_user_id'], weight=row['count'])\n",
    "    pr = nx.pagerank(G, weight='weight')\n",
    "    for user, score in pr.items():\n",
    "        pagerank_results.append({'community': community_user, 'user_id': user, 'pagerank': score})\n",
    "\n",
    "pagerank_df = pd.DataFrame(pagerank_results)\n",
    "pagerank_df = pd.merge(pagerank_df, index_df, on='user_id', how='outer').fillna(0)\n",
    "pagerank_df = pagerank_df.sort_values(['community', 'pagerank'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree = df_same_community.groupby('user_id')['count'].sum().reset_index(name='out_degree')\n",
    "in_degree = df_same_community.groupby('commented_user_id')['count'].sum().reset_index(name='in_degree')\n",
    "in_degree.rename(columns={'commented_user_id': 'user_id'}, inplace=True)\n",
    "\n",
    "degrees_community = pd.merge(out_degree, in_degree, on='user_id', how='outer').fillna(0)\n",
    "user_stats_community = pd.merge(degrees_community, index_df, on='user_id', how='outer').fillna(0)\n",
    "user_stats_community['total'] = user_stats_community['out_degree'] + user_stats_community['in_degree']\n",
    "\n",
    "final_user_stats_community = pd.merge(user_stats_community, communities, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for community in sorted(final_user_stats_community['community'].unique()):\n",
    "    community_df = final_user_stats_community[final_user_stats_community['community'] == community]\n",
    "    pagerank_top = pagerank_df[pagerank_df['community'] == community].sort_values(by='pagerank', ascending=False).head(10)\n",
    "\n",
    "    top_in_degree = community_df.sort_values(by='in_degree', ascending=False).head(10)\n",
    "    top_total = community_df.sort_values(by='total', ascending=False).head(5)\n",
    "    top_out_degree = community_df.sort_values(by='out_degree', ascending=False).head(5)\n",
    "\n",
    "    percentage_self = sym_df.loc[community, \"Percentage_Self\"] if \"Percentage_Self\" in sym_df.columns else 0.0\n",
    "    row = sym_df.loc[community].drop(labels=[\"Percentage_Self\"], errors=\"ignore\")\n",
    "    if community in row.index:\n",
    "        row = row.drop(community)\n",
    "    total_other = row.sum()\n",
    "    top3 = row.nlargest(3) if total_other != 0 else pd.Series()\n",
    "\n",
    "    print(f\"\\n===== Community {community} =====\")\n",
    "    print(f\"Size: {len(community_df)} users\")\n",
    "    \n",
    "    print(\"\\nTop 10 users by PageRank:\")\n",
    "    print(pagerank_top[['name', 'pagerank']].reset_index(drop=True))\n",
    "\n",
    "    print(\"\\nTop 10 by In Degree:\")\n",
    "    print(top_in_degree[['name', 'in_degree']].reset_index(drop=True))\n",
    "\n",
    "    print(\"\\nTop 5 by Out Degree:\")\n",
    "    print(top_out_degree[['name', 'out_degree']].reset_index(drop=True))\n",
    "\n",
    "    print(\"\\nTop 5 by Total Degree:\")\n",
    "    print(top_total[['name', 'total']].reset_index(drop=True))\n",
    "\n",
    "    print(f\"\\nPercentage of interactions within same community: {percentage_self:.2f}%\")\n",
    "    \n",
    "    print(\"Most interacted with communities:\")\n",
    "    if top3.empty:\n",
    "        print(\"None.\")\n",
    "    else:\n",
    "        for comm, count in top3.items():\n",
    "            pct = (count / total_other) * 100\n",
    "            print(f\"Community {comm}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_sizes = (\n",
    "    final_user_stats_community.groupby('community')\n",
    "    .size()\n",
    "    .reset_index(name='size')\n",
    "    .sort_values(by='size', ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='community', y='size', data=community_sizes, palette='viridis', hue='community', legend=False)\n",
    "plt.title('Community Sizes')\n",
    "plt.xlabel('Community ID')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "percentage_self_df = sym_df[['Percentage_Self']].reset_index().rename(columns={'index': 'community'})\n",
    "percentage_self_df['Percentage_Self'] = percentage_self_df['Percentage_Self'].astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='community', y='Percentage_Self', data=percentage_self_df, palette='coolwarm')\n",
    "plt.title('Percentage of Intra-Community Interactions (Self)')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "interaction_pct_df = sym_df.drop(columns='Percentage_Self').copy()\n",
    "\n",
    "interaction_pct_normalized = interaction_pct_df.div(interaction_pct_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "interaction_pct_normalized.fillna(0, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    interaction_pct_normalized,\n",
    "    cmap='YlGnBu',\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cbar_kws={'label': 'Percentage of Interactions (%)'}\n",
    ")\n",
    "plt.title('Community Interaction Heatmap (Percentage of Total Interactions Per Community)')\n",
    "plt.xlabel('Interacted With Community')\n",
    "plt.ylabel('From Community')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
